{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3c2928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from data_loader import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f0edaa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#selecting device as per GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a5d93b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolutional layer\n",
    "class Conv(nn.Module):\n",
    "    \n",
    "    def __init__(self, kernel_size, stride=1, padding=True, kernel_tensor=None):\n",
    "        super(Conv, self).__init__()\n",
    "        self.initialize_params(kernel_size, stride, padding, kernel_tensor)\n",
    "    \n",
    "    #Function to initialize nn model params\n",
    "    def initialize_params(self, kernel_size, stride, padding, kernel_tensor):\n",
    "            \n",
    "            self.kernel_size = kernel_size\n",
    "            self.stride = stride\n",
    "            self.padding = padding\n",
    "            \n",
    "            self.padding_layer = nn.ZeroPad2d(self.kernel_size//2)\n",
    "            \n",
    "            if kernel_tensor is None:\n",
    "                self.kernel = nn.Parameter(torch.randint(0, 2, (self.kernel_size, self.kernel_size), dtype=torch.float))\n",
    "            else:\n",
    "                self.kernel = nn.Parameter(kernel_tensor)\n",
    "                \n",
    "            \n",
    "            \n",
    "    #forward pass of the nn model\n",
    "    \n",
    "    def forward(self, image):\n",
    "        \n",
    "        if self.padding:\n",
    "            padded_image = self.padding_layer(image)\n",
    "        else:\n",
    "            padded_image = image\n",
    "        \n",
    "        stop = self.kernel_size - 1\n",
    "        target_shape = padded_image.shape[-2] - stop, padded_image.shape[-1] - stop\n",
    "        \n",
    "        conv_imgs = torch.zeros((image.shape[0], image.shape[1], target_shape[0], target_shape[1])).to(device)\n",
    "        \n",
    "        for n in range(padded_image.shape[0]):\n",
    "            for c in range(padded_image.shape[1]):\n",
    "                conv_img = list()\n",
    "                temp_img = padded_image[n][c]\n",
    "                for i in range(padded_image.shape[2] - stop):\n",
    "                    for j in range(padded_image.shape[3] - stop):\n",
    "                        temp_img_view = temp_img[i : i + self.kernel_size, j : j + self.kernel_size]\n",
    "                        conv_img.append(torch.sum(torch.mul(temp_img_view, self.kernel)))\n",
    "                conv_img = torch.stack(conv_img)\n",
    "                conv_img = torch.reshape(conv_img, target_shape)\n",
    "                conv_img = torch.unsqueeze(conv_img, 0)\n",
    "            conv_imgs[n] = conv_img\n",
    "        return conv_imgs\n",
    "    \n",
    "def get_torch_conv(image, kernel, padding=0):\n",
    "    return F.conv2d(image, kernel, padding=padding)\n",
    "\n",
    "\n",
    "def __reshape_before_conv__(X):\n",
    "    X = torch.reshape(X, (X.shape[0]*X.shape[1], 1, 16, 8))\n",
    "    print(X.shape)\n",
    "    return X\n",
    "\n",
    "\n",
    "def __reshape_after_conv__(X):\n",
    "    X = torch.reshape(X, (X.shape[0]//14, 14, X.shape[2]*X.shape[3]))\n",
    "    print(X.shape)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c87cb052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[2., 2., 3., 1., 1.],\n",
      "          [1., 4., 3., 4., 1.],\n",
      "          [1., 2., 4., 3., 3.],\n",
      "          [1., 2., 3., 4., 1.],\n",
      "          [0., 2., 2., 1., 1.]]]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "tensor([[[[2., 2., 3., 1., 1.],\n",
      "          [1., 4., 3., 4., 1.],\n",
      "          [1., 2., 4., 3., 3.],\n",
      "          [1., 2., 3., 4., 1.],\n",
      "          [0., 2., 2., 1., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "#Test Case for Conv Forward pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image = torch.tensor([[1,1,1,0,0],[0,1,1,1,0],[0,0,1,1,1],[0,0,1,1,0],[0,1,1,0,0]], dtype=torch.float)\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    kernel = torch.tensor([[1, 0, 1],[0, 1, 0],[1, 0, 1]], dtype=torch.float)\n",
    "    conv = Conv(3, kernel_tensor=kernel)\n",
    "    print(conv(image))\n",
    "\n",
    "    # check with PyTorch implementation\n",
    "    kernel = torch.unsqueeze(kernel, 0)\n",
    "    kernel = torch.unsqueeze(kernel, 0)\n",
    "    print(get_torch_conv(image, kernel, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "517d36fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATALOADER!!!\n",
      "torch.Size([2, 14, 128])\n",
      "torch.Size([28, 1, 16, 8])\n",
      "torch.Size([28, 1, 16, 8])\n",
      "torch.Size([2, 14, 128])\n"
     ]
    }
   ],
   "source": [
    " # test with data loader\n",
    "print(\"DATALOADER!!!\")\n",
    "dataset = get_dataset()\n",
    "split = int(0.5 * len(dataset.data)) # train-test split\n",
    "train_data, test_data = dataset.data[:split], dataset.data[split:]\n",
    "train_target, test_target = dataset.target[:split], dataset.target[split:]\n",
    "train = data_utils.TensorDataset(torch.tensor(train_data).float(), torch.tensor(train_target).long())\n",
    "train_loader = data_utils.DataLoader(train,  batch_size=2, shuffle=True, sampler=None, num_workers=1, pin_memory=False)\n",
    "for i_batch, sample in enumerate(train_loader):\n",
    "    train_sample = sample[0]\n",
    "    print(train_sample.shape)\n",
    "    X = __reshape_before_conv__(train_sample)\n",
    "    feat = conv(X)\n",
    "    print(feat.shape)\n",
    "    __reshape_after_conv__(feat)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee067113",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-99f809adca1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_tensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# check with PyTorch implementation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\CS512_Project\\Lab_2\\code\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0mpadded_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mpadded_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_torch_conv(image, kernel, padding=0):\n",
    "    return F.conv2d(image, kernel, padding=padding)\n",
    "\n",
    "image = torch.tensor([[1,1,1,0,0],[0,1,1,1,0],[0,0,1,1,1],[0,0,1,1,0],[0,1,1,0,0]], dtype=torch.float)\n",
    "image = torch.unsqueeze(image, 0)\n",
    "image = torch.unsqueeze(image, 0)\n",
    "kernel = torch.tensor([[1, 0, 1],[0, 1, 0],[1, 0, 1]], dtype=torch.float)\n",
    "conv = Conv(3, kernel_tensor=kernel)\n",
    "print(conv(image))\n",
    "\n",
    "# check with PyTorch implementation\n",
    "kernel = torch.unsqueeze(kernel, 0)\n",
    "kernel = torch.unsqueeze(kernel, 0)\n",
    "print(get_torch_conv(image, kernel, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
